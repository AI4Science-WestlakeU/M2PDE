{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.filepath import ABSOLUTE_PATH\n",
    "from src.model.diffusion import GaussianDiffusion\n",
    "from src.model.UNet2d import Unet2D\n",
    "from src.model.fno import FNO2D\n",
    "from src.inference.compose import compose_diffusion\n",
    "from src.utils.utils import plot_compare_2d, relative_error\n",
    "from src.train.reaction_diffusion import cond_emb, renormalize\n",
    "from src.train.reaction_diffusion import normalize_to_neg_one_to_one as normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"FNO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 24\n",
    "out_dim = 1\n",
    "channel = 3\n",
    "nx = 20\n",
    "diffusion_step = 250\n",
    "device = \"cuda\"\n",
    "if model_type == \"Unet\":\n",
    "    model1 = Unet2D(dim=dim, cond_emb=cond_emb(), out_dim=out_dim, dim_mults=(1, 2), channels=channel)\n",
    "    model2 = Unet2D(dim=dim, cond_emb=cond_emb(), out_dim=out_dim, dim_mults=(1, 2), channels=channel)\n",
    "elif model_type == \"ViT\":\n",
    "    model1 = ViT(\n",
    "        seq_len=20,\n",
    "        patch_size=2,\n",
    "        dim=64,\n",
    "        depth=2,\n",
    "        heads=8,\n",
    "        mlp_dim=128,\n",
    "        cond_emb=cond_emb(),\n",
    "        Time_Input=True,\n",
    "        dropout=0.0,\n",
    "        emb_dropout=0.0,\n",
    "        channels=20,\n",
    "        out_channels=9,\n",
    "    ).to(\"cuda\")\n",
    "    model2 = ViT(\n",
    "        seq_len=20,\n",
    "        patch_size=2,\n",
    "        dim=64,\n",
    "        depth=2,\n",
    "        heads=8,\n",
    "        mlp_dim=128,\n",
    "        cond_emb=cond_emb(),\n",
    "        Time_Input=True,\n",
    "        dropout=0.0,\n",
    "        emb_dropout=0.0,\n",
    "        channels=20,\n",
    "        out_channels=9,\n",
    "    ).to(\"cuda\")\n",
    "elif model_type == \"FNO\":\n",
    "    model1 = FNO2D(\n",
    "        in_channels=channel,\n",
    "        out_channels=out_dim,\n",
    "        nr_fno_layers=4,\n",
    "        fno_layer_size=24,\n",
    "        fno_modes=[6, 12],\n",
    "        time_input=True,\n",
    "        cond_emb=cond_emb(),\n",
    "    )\n",
    "    model2 = FNO2D(\n",
    "        in_channels=channel,\n",
    "        out_channels=out_dim,\n",
    "        nr_fno_layers=4,\n",
    "        fno_layer_size=24,\n",
    "        fno_modes=[6, 12],\n",
    "        time_input=True,\n",
    "        cond_emb=cond_emb(),\n",
    "    )\n",
    "diffusion1 = GaussianDiffusion(model1, seq_length=(out_dim, 10, nx), timesteps=diffusion_step, auto_normalize=False).to(\n",
    "    device\n",
    ")\n",
    "diffusion2 = GaussianDiffusion(model2, seq_length=(out_dim, 10, nx), timesteps=diffusion_step, auto_normalize=False).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"Unet\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionUnetu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionUnetv10000/model.pt\")[\"model\"])\n",
    "elif model_type == \"ViT\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionViTu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionViTv10000/model.pt\")[\"model\"])\n",
    "elif model_type == \"FNO\":\n",
    "    diffusion1.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionFNOu10000/model.pt\")[\"model\"])\n",
    "    diffusion2.load_state_dict(torch.load(\"../../results/reaction_diffusion/diffusionFNOv10000/model.pt\")[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation of u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10, 101):\n",
    "#     diffusion2.load_state_dict(\n",
    "#         torch.load(\"../../results/reaction_diffusion/diffusionFNOu10000/model-\" + str(i) + \".pt\")[\"model\"]\n",
    "#     )\n",
    "data = (\n",
    "    torch.tensor(np.load(\"../../data/reaction_diffusion/reaction_diffusion_u_from_v_u.npy\")).float().to(\"cuda\")[9000:]\n",
    ")\n",
    "cond = (\n",
    "    torch.tensor(np.load(\"../../data/reaction_diffusion/reaction_diffusion_u_from_v_v.npy\")).float().to(\"cuda\")[9000:]\n",
    ")\n",
    "\n",
    "data = torch.tensor(data).unsqueeze(1)\n",
    "\n",
    "cond1 = torch.tensor(cond).unsqueeze(1)\n",
    "\n",
    "cond2 = data[:, :, 0:1].clone().expand(-1, -1, data.shape[2], -1)\n",
    "\n",
    "cond = torch.concat((cond1, cond2), dim=1)\n",
    "\n",
    "u_pred = renormalize(diffusion1.sample(cond.shape[0], cond=[normalize(cond)]))\n",
    "\n",
    "rmse = relative_error(data, u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_n = np.random.randint(0, data.shape[0])\n",
    "plot_compare_2d(\n",
    "    true_d=data[random_n, 0],\n",
    "    pred_d=u_pred[random_n, 0],\n",
    ")\n",
    "# plot_compare_2d(data, un(u_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation of v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(51, 91):\n",
    "#     diffusion2.load_state_dict(\n",
    "#         torch.load(\"../../results/reaction_diffusion/diffusionFNOv10000/model-\" + str(i) + \".pt\")[\"model\"]\n",
    "#     )\n",
    "data = (\n",
    "    torch.tensor(np.load(\"../../data/reaction_diffusion/reaction_diffusion_v_from_u_v.npy\")).float().to(\"cuda\")[9000:]\n",
    ")\n",
    "cond = (\n",
    "    torch.tensor(np.load(\"../../data/reaction_diffusion/reaction_diffusion_v_from_u_u.npy\")).float().to(\"cuda\")[9000:]\n",
    ")\n",
    "\n",
    "\n",
    "data = torch.tensor(data).unsqueeze(1)\n",
    "\n",
    "\n",
    "cond1 = torch.tensor(cond).unsqueeze(1)\n",
    "\n",
    "\n",
    "cond2 = data[:, :, 0:1].clone().expand(-1, -1, data.shape[2], -1)\n",
    "\n",
    "\n",
    "cond = torch.concat((cond1, cond2), dim=1)\n",
    "\n",
    "\n",
    "v_pred = renormalize(diffusion2.sample(cond.shape[0], cond=[normalize(cond)]))\n",
    "\n",
    "\n",
    "rmse = relative_error(data, v_pred)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_n = np.random.randint(0, data.shape[0])\n",
    "plot_compare_2d(\n",
    "    true_d=data[random_n, 0],\n",
    "    pred_d=(v_pred)[random_n, 0],\n",
    ")\n",
    "# plot_compare_2d(data, un(u_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    torch.tensor(np.load(ABSOLUTE_PATH + \"/data/reaction_diffusion/reaction_diffusion_uv.npy\"))\n",
    "    .float()\n",
    "    .to(\"cuda\")[:2000]\n",
    ")\n",
    "# data = (data + 5) / 10\n",
    "\n",
    "data = data.permute(0, 2, 1)\n",
    "\n",
    "# data1 = np.load('../../data/reaction_diffusion_u_from_v_u.npy')\n",
    "\n",
    "u, v = data[..., :20].unsqueeze(1), data[..., 20:].unsqueeze(1)\n",
    "\n",
    "u_intial, v_intial = u[:, :, 0:1].expand(-1, -1, 10, -1), v[:, :, 0:1].expand(-1, -1, 10, -1)\n",
    "\n",
    "u.shape, u_intial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_u(\n",
    "    alpha, t, model, field_noise, mult_p_estimate, mult_p_estimate_before, other_condition, normalize, renormalize\n",
    "):\n",
    "    weight_field = []\n",
    "    for i in range(len(mult_p_estimate)):\n",
    "        weight_field.append(alpha * mult_p_estimate[i] + (1 - alpha) * mult_p_estimate_before[i])\n",
    "    intial_u, intial_v = other_condition[0], other_condition[1]\n",
    "    cond = [torch.concat((weight_field[1], intial_u), dim=1)]\n",
    "    field_noise_next, x0 = model.p_sample(field_noise, t, cond)\n",
    "    return field_noise_next, x0\n",
    "\n",
    "\n",
    "def update_v(\n",
    "    alpha, t, model, field_noise, mult_p_estimate, mult_p_estimate_before, other_condition, normalize, renormalize\n",
    "):\n",
    "    weight_field = []\n",
    "    for i in range(len(mult_p_estimate)):\n",
    "        weight_field.append(alpha * mult_p_estimate[i] + (1 - alpha) * mult_p_estimate_before[i])\n",
    "    intial_u, intial_v = other_condition[0], other_condition[1]\n",
    "    cond = [torch.concat((weight_field[0], intial_v), dim=1)]\n",
    "    field_noise_next, x0 = model.p_sample(field_noise, t, cond)\n",
    "    return field_noise_next, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lis = [diffusion1, diffusion2]\n",
    "mult_p = compose_diffusion(\n",
    "    model_list=model_lis,\n",
    "    shape=[(u.shape[0], 1, 10, 20), (u.shape[0], 1, 10, 20)],\n",
    "    other_condition=[normalize(u_intial), normalize(v_intial)],\n",
    "    update_f=[update_u, update_v],\n",
    "    normalize_f=[normalize, normalize],\n",
    "    unnormalize_f=[renormalize, renormalize],\n",
    "    num_iter=2,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_p_true = torch.concat((u, v), dim=1)\n",
    "mult_p_pred = renormalize(torch.concat((mult_p[0], mult_p[1]), dim=1))\n",
    "\n",
    "\n",
    "mult_p_true.shape, mult_p_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(mult_p_pred[:, 0], mult_p_true[:, 0]), relative_error(mult_p_pred[:, 1], mult_p_true[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter 1  \n",
    "use trick 1.70e-2 1.95e-2   \n",
    "unuse trick 1.69e-2 1.95e-2\n",
    "\n",
    "iter 2  \n",
    "use trick 1.70e-2 1.94e-2   \n",
    "unuse trick 1.68e-2 1.94e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tensor(8.9275e-06, device='cuda:0'),\n",
    " tensor(1.4842e-05, device='cuda:0'),\n",
    " tensor(3.0127e-06, device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_n = np.random.randint(0, data.shape[0])\n",
    "random_n = -1\n",
    "\n",
    "\n",
    "plot_compare_2d(\n",
    "    true_d=mult_p_true[random_n, 1],\n",
    "    pred_d=mult_p_pred[random_n, 1],\n",
    "    savep=ABSOLUTE_PATH + \"/results/reaction_diffusion/diffusion.pdf\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cindm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
