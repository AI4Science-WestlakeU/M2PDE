{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src.filepath import ABSOLUTE_PATH\n",
    "from src.train.heatpipe import load_data, renormalize\n",
    "from src.model.transolver import Transolver\n",
    "from src.model.GeoFNO import GeoFNO2d as FNO\n",
    "from src.utils.utils import relative_error, to_np, plot_scatter_compare, find_max_min\n",
    "from src.model.diffusion import GaussianDiffusion\n",
    "from src.inference.compose import compose_diffusion_multiE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "diffusion_step = 250\n",
    "model_type = \"transformer\"\n",
    "train_loader, test_loader = load_data(ABSOLUTE_PATH, 64, 14000, model_type=model_type, device=device)\n",
    "del train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"transformer\":\n",
    "    model = Transolver(\n",
    "        space_dim=2,\n",
    "        n_layers=5,\n",
    "        n_hidden=64,\n",
    "        dropout=0.0,\n",
    "        n_head=8,\n",
    "        Time_Input=True,\n",
    "        act=\"gelu\",\n",
    "        mlp_ratio=1,\n",
    "        fun_dim=13,\n",
    "        out_dim=3,\n",
    "        slice_num=16,\n",
    "        ref=8,\n",
    "        unified_pos=False,\n",
    "    ).to(device)\n",
    "elif model_type == \"FNO\":\n",
    "    modes = [8, 8, 8]\n",
    "    model = FNO(\n",
    "        modes1=modes[0], modes2=modes[1], modes3=modes[2], width=32, in_channels=13, out_channels=3, time_input=True\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    seq_length=tuple([804, 3]),\n",
    "    timesteps=diffusion_step,\n",
    "    auto_normalize=False,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "diffusion.load_state_dict(torch.load(\"../../results/heatpipe/diffusion/\" + model_type + \"/model.pt\")[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_n_T = 0\n",
    "mae_T = 0\n",
    "rmae_T = 0\n",
    "mae_n_s = 0\n",
    "mae_s = 0\n",
    "rmae_s = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        coord, fx, y = batch\n",
    "        batchsize = y.shape[0]\n",
    "\n",
    "        data_pred_n = diffusion.sample(batchsize, (coord, fx))\n",
    "        data_pred = renormalize(data_pred_n)\n",
    "        data_true_n = y\n",
    "        data_true = renormalize(y)\n",
    "\n",
    "        mae_n_T += torch.mean(torch.abs(data_true_n[..., 0:1] - data_pred_n[..., 0:1]))\n",
    "        mae_T += torch.mean(torch.abs(data_true[..., 0:1] - data_pred[..., 0:1]))\n",
    "        rmae_T += relative_error(data_true[..., 0:1], data_pred[..., 0:1])\n",
    "        mae_n_s += torch.mean(torch.abs(data_true_n[..., 1:] - data_pred_n[..., 1:]))\n",
    "        mae_s += torch.mean(torch.abs(data_true[..., 1:] - data_pred[..., 1:]))\n",
    "        rmae_s += relative_error(data_true[..., 1:], data_pred[..., 1:])\n",
    "mae_n_T, mae_T, rmae_T = mae_n_T / len(test_loader), mae_T / len(test_loader), rmae_T / len(test_loader)\n",
    "mae_n_s, mae_s, rmae_s = mae_n_s / len(test_loader), mae_s / len(test_loader), rmae_s / len(test_loader)\n",
    "mae_n_T, mae_T, rmae_T, mae_n_s, mae_s, rmae_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_n = np.random.randint(0, data_pred.shape[0])\n",
    "phy_tag = np.random.randint(0, 3)\n",
    "coord_x = to_np(coord[batch_n, :, 0])\n",
    "coord_y = to_np(coord[batch_n, :, 1])\n",
    "data_pred_np = to_np(data_pred[batch_n, :, phy_tag])\n",
    "data_true_np = to_np(data_true[batch_n, :, phy_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(coord_x, coord_y, data_true_np, data_pred_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val in 16 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load(\"../../data/heatpipe/x.npy\").reshape(-1, 16, 804, 10)\n",
    "# y = np.load(\"../../data/heatpipe/y.npy\").reshape(-1, 16, 804, 3)\n",
    "# n_batch = 0  # np.random.randint(0, 1000)\n",
    "# x = torch.tensor(x[n_batch]).to(device).float()\n",
    "# data_true = torch.tensor(y[batch_n]).to(device).float()\n",
    "x = torch.tensor(np.load(\"../../data/heatpipe/x.npy\")[:16]).to(device).float()\n",
    "y = torch.tensor(np.load(\"../../data/heatpipe/y.npy\")[:16]).to(device).float()\n",
    "data_true = to_np(renormalize(y))\n",
    "if model_type == \"FNO\":\n",
    "    coord = torch.zeros(x.shape[1], 3).to(device)\n",
    "    coordxy = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord.npy\")).to(device).float()\n",
    "    coordxy[:, 0] = (coordxy[:, 0] - 0.0455) / (0.065345 - 0.0455)\n",
    "    coordxy[:, 1] = (coordxy[:, 1] - 0.072) / (0.08918 - 0.072)\n",
    "    coord[:, :-1] = coordxy\n",
    "    coord = coord.expand(x.shape[0], -1, -1)\n",
    "else:\n",
    "    coord = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord.npy\")).to(device).float()\n",
    "    coord[:, 0] = (coord[:, 0] - 0.0455) / (0.065345 - 0.0455) * 2 - 1\n",
    "    coord[:, 1] = (coord[:, 1] - 0.072) / (0.08918 - 0.072) * 2 - 1\n",
    "    coord = coord.expand(x.shape[0], -1, -1)\n",
    "y_p = to_np(renormalize(diffusion.sample(y.shape[0], (coord, x))))\n",
    "coord.shape, data_true.shape, x.shape, data_true.shape, y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(data_true[..., 0], y_p[..., 0]), relative_error(data_true[..., 1:], y_p[..., 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1 = np.load(\"../../data/heatpipe/1/bc.npy\")\n",
    "bc2 = np.load(\"../../data/heatpipe/2/bc.npy\")\n",
    "bc = np.concatenate((bc1, bc2), axis=0)\n",
    "x = np.load(\"../../data/heatpipe/x.npy\").reshape(-1, 16, 804, 10)\n",
    "y = np.load(\"../../data/heatpipe/y.npy\").reshape(-1, 16, 804, 3)\n",
    "\n",
    "batch_n = 903  # np.random.randint(0, 1000)\n",
    "x = torch.tensor(x[batch_n]).to(device).float()\n",
    "flux = x[:, -1, -1]\n",
    "data_true = torch.tensor(y[batch_n]).to(device).float()\n",
    "data_true = to_np(renormalize(data_true))\n",
    "data_true.shape, x.shape, data_true.shape, bc[batch_n], batch_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(\n",
    "    alpha,\n",
    "    t,\n",
    "    model,\n",
    "    neighbors,\n",
    "    cond_shape,\n",
    "    boundary_emb,\n",
    "    mult_e_noise,\n",
    "    mult_e_estimate,\n",
    "    mult_e_estimate_before,\n",
    "    other_condition,\n",
    "    normalize=nn.Identity(),\n",
    "    renormalize=nn.Identity(),\n",
    "):\n",
    "    # boundary in neighbors should corrspond with boundary\n",
    "    device = mult_e_estimate.device\n",
    "    n_element, n_node = mult_e_estimate.shape[0], mult_e_estimate.shape[1]\n",
    "    channel = mult_e_estimate.shape[-1]\n",
    "    node_feature = torch.zeros((n_element, n_node) + (cond_shape,)).to(device)\n",
    "    coord = other_condition[0]\n",
    "    flux = other_condition[1]\n",
    "\n",
    "    weight_field = mult_e_estimate_before * (1 - alpha) + mult_e_estimate * alpha\n",
    "\n",
    "    for i in range(n_element):\n",
    "        for j, neighbor in enumerate(neighbors[i + 1]):\n",
    "            if not isinstance(neighbor, int):\n",
    "                b_emb = torch.tensor(boundary_emb(neighbor)).to(device)\n",
    "                node_feature[i, :, j * channel : j * channel + channel] = b_emb\n",
    "            else:\n",
    "                node_feature[i, :, j * channel : j * channel + channel] = weight_field[neighbor - 1]\n",
    "        node_feature[i, :, (j + 1) * channel :] = flux[i]\n",
    "    mult_e_noise_next, x0 = model.p_sample(mult_e_noise, t, (coord, node_feature))\n",
    "    return mult_e_noise_next, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_emb_f(b_type, n_nods=804):\n",
    "    free_emb = np.array([0, 0, 0])  # np.ones((1, 8)) * -1\n",
    "    sym_emb = np.array([0, 1, 1])  # np.ones((1, 8)) * -2\n",
    "    if b_type == \"sym\":\n",
    "        return np.tile(sym_emb, (n_nods, 1))\n",
    "    elif b_type == \"free\":\n",
    "        return np.tile(free_emb, (n_nods, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_transform(coord):\n",
    "\n",
    "    move_dis = 1 * np.array(\n",
    "        [\n",
    "            [0, 0],\n",
    "            [-0.013856407, -0.024],\n",
    "            [0.013856406, -0.024],\n",
    "            [-0.027712807, -0.048],\n",
    "            [0.0, -0.048],\n",
    "            [0.027712813, -0.048],\n",
    "            [-0.041569220, -0.072],\n",
    "            [-0.013856407, -0.072],\n",
    "            [0.013856406, -0.0720],\n",
    "            [0.0415692190, -0.072],\n",
    "            [0, 0],\n",
    "            [-0.013856407, -0.024],\n",
    "            [0.013856406, -0.024],\n",
    "            [-0.027712807, -0.048],\n",
    "            [0.0, -0.048],\n",
    "            [0.027712813, -0.048],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sym = [-1] * 10 + [0.072, 0.072, 0.072, 0.072, 0.072, 0.072]\n",
    "\n",
    "    def sym_block(y_coords, sym_axis):\n",
    "        if sym_axis < 0:\n",
    "            return y_coords\n",
    "        else:\n",
    "            sym_y_coords = 2 * sym_axis - y_coords\n",
    "            return sym_y_coords\n",
    "\n",
    "    coord_new = torch.zeros_like(coord)\n",
    "    if model_type == \"FNO\":\n",
    "        coord_new[:, :, 0] = (coord[:, :, 0]) * (0.065345 - 0.0455) + 0.0455\n",
    "        coord_new[:, :, 1] = (coord[:, :, 1]) * (0.08918 - 0.072) + 0.072\n",
    "    else:\n",
    "        coord_new[:, :, 0] = (coord[:, :, 0] + 1) / 2 * (0.065345 - 0.0455) + 0.0455\n",
    "        coord_new[:, :, 1] = (coord[:, :, 1] + 1) / 2 * (0.08918 - 0.072) + 0.072\n",
    "    for i in range(move_dis.shape[0]):\n",
    "        coord_new[i, :, 0] = coord_new[i, :, 0] + move_dis[i][0]\n",
    "        coord_new[i, :, 1] = sym_block(coord_new[i, :, 1], sym[i])\n",
    "        coord_new[i, :, 1] = coord_new[i, :, 1] + move_dis[i][1]\n",
    "    # coord_new = to_np(coord_new.reshape(-1, 2))\n",
    "    # coord_new_x = coord_new[:, 0]\n",
    "    # coord_new_y = coord_new[:, 1]\n",
    "    return coord_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = \"free\" if all(x == y for x, y in zip(bc[batch_n, 0], [0, 0, 0])) else \"sym\"\n",
    "right = \"free\" if all(x == y for x, y in zip(bc[batch_n, 1], [0, 0, 0])) else \"sym\"\n",
    "bottom = \"free\" if all(x == y for x, y in zip(bc[batch_n, 2], [0, 0, 0])) else \"sym\"\n",
    "# left = \"free\"\n",
    "# right = \"free\"\n",
    "# bottom = (renomalize_disp(-0.0832), renomalize_disp(-0.2587))  # \"fix\"\n",
    "neighbors = {\n",
    "    1: (left, right, 11),\n",
    "    2: (left, 11, 12),\n",
    "    3: (11, right, 13),\n",
    "    4: (left, 12, 14),\n",
    "    5: (12, 13, 15),\n",
    "    6: (13, right, 16),\n",
    "    7: (left, 14, bottom),\n",
    "    8: (14, 15, bottom),\n",
    "    9: (15, 16, bottom),\n",
    "    10: (16, right, bottom),\n",
    "    11: (3, 2, 1),\n",
    "    12: (5, 4, 2),\n",
    "    13: (6, 5, 3),\n",
    "    14: (8, 7, 4),\n",
    "    15: (9, 8, 5),\n",
    "    16: (10, 9, 6),\n",
    "}\n",
    "left, right, bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_e = compose_diffusion_multiE(\n",
    "    model=diffusion,\n",
    "    shape=(804, 3),\n",
    "    cond_shape=10,\n",
    "    update_f=update,\n",
    "    adj=neighbors,\n",
    "    boundary_emb=boundary_emb_f,\n",
    "    other_condition=[coord, flux],\n",
    "    num_iter=3,\n",
    ")\n",
    "mult_e.shape, data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = to_np(renormalize(mult_e))\n",
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(data_true[..., :1], data_pred[..., :1]), relative_error(data_true[..., 1:], data_pred[..., 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(data_true.reshape(-1, 3)[..., :1], data_pred.reshape(-1, 3)[..., :1]), relative_error(\n",
    "    data_true[..., 1:].reshape(-1, 3), data_pred[..., 1:].reshape(-1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_new = coord_transform(coord)\n",
    "coord_new = to_np(coord_new.reshape(-1, 2))\n",
    "coord_new_x = coord_new[:, 0]\n",
    "coord_new_y = coord_new[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    coord_new_x,\n",
    "    coord_new_y,\n",
    "    to_np(data_true)[..., 0].reshape(-1),\n",
    "    to_np(data_pred)[..., 0].reshape(-1),\n",
    "    figsize=(35, 8),\n",
    "    fontsize=0.1,\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/T.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    coord_new_x,\n",
    "    coord_new_y,\n",
    "    to_np(data_true)[..., 1].reshape(-1),\n",
    "    to_np(data_pred)[..., 1].reshape(-1),\n",
    "    figsize=(35, 8),\n",
    "    fontsize=0.1,\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/strainx.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    coord_new_x,\n",
    "    coord_new_y,\n",
    "    to_np(data_true)[..., 2].reshape(-1),\n",
    "    to_np(data_pred)[..., 2].reshape(-1),\n",
    "    figsize=(35, 8),\n",
    "    fontsize=0.1,\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/strainy.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = \"sym\"\n",
    "right = \"free\"\n",
    "bottom = \"sym\"\n",
    "# left = \"free\"\n",
    "# right = \"free\"\n",
    "# bottom = (renomalize_disp(-0.0832), renomalize_disp(-0.2587))  # \"fix\"\n",
    "neighbors = {\n",
    "    # 1\n",
    "    1: (left, right, 11),\n",
    "    2: (left, 11, 12),\n",
    "    3: (11, right, 13),\n",
    "    4: (left, 12, 14),\n",
    "    5: (12, 13, 15),\n",
    "    6: (13, right, 16),\n",
    "    7: (left, 14, 26),\n",
    "    8: (14, 15, 25),\n",
    "    9: (15, 16, 24),\n",
    "    10: (16, right, 23),\n",
    "    11: (3, 2, 1),\n",
    "    12: (5, 4, 2),\n",
    "    13: (6, 5, 3),\n",
    "    14: (8, 7, 4),\n",
    "    15: (9, 8, 5),\n",
    "    16: (10, 9, 6),\n",
    "    17: (55, 42, 27),\n",
    "    18: (52, 27, 28),\n",
    "    19: (27, 38, 29),\n",
    "    20: (50, 28, 30),\n",
    "    21: (28, 29, 31),\n",
    "    22: (29, 35, 32),\n",
    "    23: (49, 30, 10),\n",
    "    24: (30, 31, 9),\n",
    "    25: (31, 32, 8),\n",
    "    26: (32, 33, 7),\n",
    "    27: (19, 18, 17),\n",
    "    28: (21, 20, 18),\n",
    "    29: (22, 21, 19),\n",
    "    30: (24, 23, 20),\n",
    "    31: (25, 24, 21),\n",
    "    32: (26, 25, 22),\n",
    "    33: (left, 26, 43),\n",
    "    34: (left, 43, 44),\n",
    "    35: (43, 22, 45),\n",
    "    36: (left, 44, 46),\n",
    "    37: (44, 45, 47),\n",
    "    38: (45, 19, 48),\n",
    "    39: (left, 46, bottom),\n",
    "    40: (46, 47, bottom),\n",
    "    41: (47, 48, bottom),\n",
    "    42: (48, 17, bottom),\n",
    "    43: (35, 34, 33),\n",
    "    44: (37, 36, 34),\n",
    "    45: (38, 37, 35),\n",
    "    46: (40, 39, 36),\n",
    "    47: (41, 40, 37),\n",
    "    48: (42, 41, 38),\n",
    "    49: (23, right, 59),\n",
    "    50: (20, 59, 60),\n",
    "    51: (59, right, 61),\n",
    "    52: (18, 60, 62),\n",
    "    53: (60, 61, 63),\n",
    "    54: (61, right, 64),\n",
    "    55: (17, 62, bottom),\n",
    "    56: (62, 63, bottom),\n",
    "    57: (63, 64, bottom),\n",
    "    58: (64, right, bottom),\n",
    "    59: (51, 50, 49),\n",
    "    60: (53, 52, 50),\n",
    "    61: (54, 53, 51),\n",
    "    62: (56, 55, 52),\n",
    "    63: (57, 56, 53),\n",
    "    64: (58, 57, 54),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def compose_diffusion_multiE(\n",
    "    model,\n",
    "    shape,\n",
    "    cond_shape,\n",
    "    update_f,\n",
    "    adj,\n",
    "    boundary_emb,\n",
    "    normalize_f=nn.Identity(),\n",
    "    unnormalize_f=nn.Identity(),\n",
    "    other_condition=[],\n",
    "    num_iter=2,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"compose diffusion model for multi element.\n",
    "\n",
    "    Args:\n",
    "        model: conditional diffusion model.\n",
    "        shape: shape of field.\n",
    "        update_f: update function physics field.\n",
    "        adj (dict): neighbor for each element.\n",
    "        normalize_f (_type_, optional): normalization function for each physics field.\n",
    "        unnormalize_f (_type_, optional): unnormalization function for each physics field.\n",
    "        boundary_emb: emb function for boundary.\n",
    "        other_condition (list): other_condition such as initial state, source term. The shape of list element is b, *\n",
    "        unnormalize (_type_, optional): unnormalization function for different physics field. Defaults to identity.\n",
    "        num_iter: (int, optional): outer iteration. Defaults to 2.\n",
    "        device (str, optional): _description_. Defaults to 'cuda'.\n",
    "    Returns:\n",
    "        Tensor: a tensor of multiphysics field\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        n_compose = len(adj)\n",
    "\n",
    "        timestep = model.num_timesteps\n",
    "\n",
    "        # initial field\n",
    "        mult_e_estimate = torch.randn((n_compose,) + shape).to(device)\n",
    "        # for i in range(n_compose):\n",
    "        #     mult_p_estimate.append(torch.randn(shape, device=device))\n",
    "\n",
    "        for k in range(num_iter):\n",
    "            mult_e_estimate_before = mult_e_estimate.clone()\n",
    "            mult_e_estimate = torch.randn((n_compose,) + shape).to(device)\n",
    "            mult_e = torch.randn((n_compose,) + shape).to(device)\n",
    "            for t in tqdm(reversed(range(0, timestep)), desc=\"sampling loop time step\", total=timestep):\n",
    "                alpha = 0 if k > 0 else 1  # 1 - t / (timestep - 1)\n",
    "                single_p, x0 = update_f(\n",
    "                    alpha,\n",
    "                    t,\n",
    "                    model,\n",
    "                    adj,\n",
    "                    cond_shape,\n",
    "                    boundary_emb,\n",
    "                    mult_e.clone(),\n",
    "                    mult_e_estimate.clone(),\n",
    "                    mult_e_estimate_before.clone(),\n",
    "                    other_condition,\n",
    "                    normalize_f,\n",
    "                    unnormalize_f,\n",
    "                )\n",
    "                mult_e = single_p\n",
    "                mult_e_estimate = model.unnormalize(x0)\n",
    "    return mult_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"FNO\":\n",
    "    coord = torch.zeros(804, 3).to(device)\n",
    "    coordxy = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord.npy\")).to(device).float()\n",
    "    coordxy[:, 0] = (coordxy[:, 0] - 0.0455) / (0.065345 - 0.0455)\n",
    "    coordxy[:, 1] = (coordxy[:, 1] - 0.072) / (0.08918 - 0.072)\n",
    "    coord[:, :-1] = coordxy\n",
    "    coord = coord.expand(64, -1, -1)\n",
    "else:\n",
    "    coord = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord.npy\")).to(device).float()\n",
    "    coord[:, 0] = (coord[:, 0] - 0.0455) / (0.065345 - 0.0455) * 2 - 1\n",
    "    coord[:, 1] = (coord[:, 1] - 0.072) / (0.08918 - 0.072) * 2 - 1\n",
    "    coord = coord.expand(64, -1, -1)\n",
    "flux = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/val_flux.npy\")).to(device)\n",
    "flux = (flux - 1e5) / 9e5 * 2 - 1\n",
    "coord.shape, flux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_e = compose_diffusion_multiE(\n",
    "    model=diffusion,\n",
    "    shape=(804, 3),\n",
    "    cond_shape=10,\n",
    "    update_f=update,\n",
    "    adj=neighbors,\n",
    "    boundary_emb=boundary_emb_f,\n",
    "    other_condition=[coord, flux],\n",
    "    num_iter=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_transform2(coord):\n",
    "    base_coord = coord\n",
    "\n",
    "    coord1 = np.zeros_like(base_coord)\n",
    "    coord1[..., 0] = 2 * 0.0554256215 - base_coord[..., 0]\n",
    "    coord1[..., 1] = -base_coord[..., 1]\n",
    "\n",
    "    coord2 = np.zeros_like(base_coord)\n",
    "    coord2[..., 0] = base_coord[..., 0] - 0.055425618\n",
    "    coord2[..., 1] = base_coord[..., 1] - 0.096\n",
    "\n",
    "    coord3 = np.zeros_like(base_coord)\n",
    "    coord3[..., 0] = base_coord[..., 0] + 0.055425618\n",
    "    coord3[..., 1] = base_coord[..., 1] - 0.096\n",
    "    return np.concatenate((base_coord, coord1, coord2, coord3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_e = to_np(renormalize(mult_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = torch.tensor(np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord.npy\")).to(device).float()\n",
    "if model_type == \"FNO\":\n",
    "    coord[:, 0] = (coord[:, 0] - 0.0455) / (0.065345 - 0.0455)\n",
    "    coord[:, 1] = (coord[:, 1] - 0.072) / (0.08918 - 0.072)\n",
    "else:\n",
    "    coord[:, 0] = (coord[:, 0] - 0.0455) / (0.065345 - 0.0455) * 2 - 1\n",
    "    coord[:, 1] = (coord[:, 1] - 0.072) / (0.08918 - 0.072) * 2 - 1\n",
    "coord = coord.expand(16, -1, -1)\n",
    "\n",
    "coord = to_np(coord_transform(coord))\n",
    "coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_val = np.load(ABSOLUTE_PATH + \"/data/heatpipe/coord_val.npy\")\n",
    "val_y = np.load(ABSOLUTE_PATH + \"/data/heatpipe/val_y.npy\")\n",
    "bound = [[948, 1500], [-4e-4, 1.2e-3], [-4e-4, 1.2e-3]]\n",
    "val_y = renormalize(val_y)\n",
    "# for i in range(3):\n",
    "#     val_y[..., i] = (val_y[..., i] - bound[i][0]) / (bound[i][1] - bound[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 5e-5\n",
    "coord_struture_big = coord_transform2(to_np(coord))\n",
    "x_new, y_new = coord_struture_big[..., 0].reshape(-1), coord_struture_big[..., 1].reshape(-1)\n",
    "val_y_sorted = np.empty_like(val_y)\n",
    "for i, (x_val, y_val) in enumerate(zip(x_new, y_new)):\n",
    "    distances = np.sqrt((coord_val[:, 0] - x_val) ** 2 + (coord_val[:, 1] - y_val) ** 2)\n",
    "    min_distance_index = np.argmin(distances)\n",
    "    val_y_sorted[i] = val_y[min_distance_index]\n",
    "    if distances[min_distance_index] > tolerance:\n",
    "        print(\n",
    "            f\"Multiple matching coordinates found for ({i},{x_val}, {y_val}) within tolerance, the min distance is {distances[min_distance_index]}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_e = mult_e.reshape(-1, 3)\n",
    "relative_error(mult_e[..., :1], val_y_sorted[..., :1]), relative_error(mult_e[..., 1:], val_y_sorted[..., 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compose iter 1: 0.009071380143288493, 0.023575432065924926  \n",
    "compose iter 2: 0.008330713585394393, 0.022211745967903464  \n",
    "compose iter 3: 0.007845908769075104, 0.020640788315183692   \n",
    "compose iter 4: 0.007722183197888098, 0.020671428361806608  \n",
    "compose iter 5: 0.007497295786616642, 0.020333036594145933    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_e = mult_e.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    x_new,\n",
    "    y_new,\n",
    "    to_np(mult_e)[:, 0],\n",
    "    to_np(val_y_sorted)[:, 0],\n",
    "    figsize=(18, 4),\n",
    "    pointsize=1,\n",
    "    fontsize=15,\n",
    "    Unit_=\"K\",\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/d_val_T.png\",\n",
    "    e_max=200,\n",
    "    e_min=-200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y.shape, mult_e.reshape(-1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    x_new,\n",
    "    y_new,\n",
    "    to_np(mult_e)[:, 1],\n",
    "    to_np(val_y_sorted)[:, 1],\n",
    "    figsize=(18, 4),\n",
    "    pointsize=1,\n",
    "    fontsize=15,\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/d_val_sx.png\",\n",
    "    e_max=1.2e-3,\n",
    "    e_min=-1.2e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_compare(\n",
    "    x_new,\n",
    "    y_new,\n",
    "    to_np(mult_e)[:, 2],\n",
    "    to_np(val_y_sorted)[:, 2],\n",
    "    figsize=(18, 4),\n",
    "    pointsize=1,\n",
    "    fontsize=15,\n",
    "    savep=ABSOLUTE_PATH + \"/results/heatpipe/diffusion/d_val_sy.png\",\n",
    "    e_max=1.2e-3,\n",
    "    e_min=-1.2e-3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
